{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58096b54",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Phase-D External data downloads \n",
    "\n",
    "This notebook prepares the external datasets needed for Phase D validation.\n",
    "\n",
    "D**esign goals**\n",
    "- Provide short manual instructions where licence acceptance is required.\n",
    "- Automate downloads where a stable direct link exists.\n",
    "- Standardise folder names and file paths so later notebooks can run without guesswork.\n",
    "- Cache first behaviour, reruns should not re download if outputs exist.\n",
    "\n",
    "**Datasets covered**\n",
    "1. OS Open Greenspace polygons (manual download, then code handles extraction and normalisation)\n",
    "2. LAEI 2019 Focus Areas (automated download and extraction)\n",
    "3. PTAL Grid Values (automated download and extraction)\n",
    "4. OSM major roads cache for Camden and Islington (generated from your existing OSM PBF)\n",
    "\n",
    "# â—Note: D1 is manual download stepâ—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a550a13",
   "metadata": {},
   "source": [
    "### D0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618ec16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /home/sai/test/notebook_test\n",
      "RAW_DIR: /home/sai/test/notebook_test/data/raw\n",
      "VENUES_CLEAN: /home/sai/test/notebook_test/data/processed/venues_clean.geojson\n",
      "OSM_PBF: /home/sai/test/notebook_test/data/raw/osm/greater-london-260110.osm.pbf\n",
      "GREENS_DIR: /home/sai/test/notebook_test/data/raw/os_open_greenspace\n",
      "LAEI_DIR: /home/sai/test/notebook_test/data/raw/laei_focus_areas\n",
      "PTAL_DIR: /home/sai/test/notebook_test/data/raw/ptal\n",
      "MAJOR_ROADS_DIR: /home/sai/test/notebook_test/data/raw/osm_major_roads\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# D0 Setup and paths\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import zipfile\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import requests\n",
    "\n",
    "def now_utc_iso():\n",
    "    return datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "def sha256_file(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with Path(path).open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "NOTEBOOK_DIR = Path(\".\").resolve()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Core pipeline inputs (these should already exist from Phase A to C)\n",
    "VENUES_CLEAN = PROCESSED_DIR / \"venues_clean.geojson\"\n",
    "OSM_PBF = RAW_DIR / \"osm\" / \"greater-london-260110.osm.pbf\"\n",
    "\n",
    "# External datasets for Phase D\n",
    "GREENS_DIR = RAW_DIR / \"os_open_greenspace\"\n",
    "LAEI_DIR = RAW_DIR / \"laei_focus_areas\"\n",
    "PTAL_DIR = RAW_DIR / \"ptal\"\n",
    "MAJOR_ROADS_DIR = RAW_DIR / \"osm_major_roads\"\n",
    "\n",
    "GREENS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LAEI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PTAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MAJOR_ROADS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Outputs written by this notebook\n",
    "GREENS_EXTRACT_DIR = GREENS_DIR / \"opgrsp_essh_tq_extracted\"\n",
    "LAEI_EXTRACT_DIR = LAEI_DIR / \"laei_gis\"\n",
    "PTAL_EXTRACT_DIR = PTAL_DIR / \"ptal_grid_values\"\n",
    "MAJOR_ROADS_GPKG = MAJOR_ROADS_DIR / \"major_roads_camden_islington.gpkg\"\n",
    "\n",
    "# Provenance logs\n",
    "PROV_DIR = RAW_DIR / \"provenance_phaseD_downloads\"\n",
    "PROV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PROV_GREENS = PROV_DIR / \"provenance_os_open_greenspace.json\"\n",
    "PROV_LAEI = PROV_DIR / \"provenance_laei_focus_areas.json\"\n",
    "PROV_PTAL = PROV_DIR / \"provenance_ptal.json\"\n",
    "PROV_ROADS = PROV_DIR / \"provenance_osm_major_roads.json\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"VENUES_CLEAN:\", VENUES_CLEAN)\n",
    "print(\"OSM_PBF:\", OSM_PBF)\n",
    "print(\"GREENS_DIR:\", GREENS_DIR)\n",
    "print(\"LAEI_DIR:\", LAEI_DIR)\n",
    "print(\"PTAL_DIR:\", PTAL_DIR)\n",
    "print(\"MAJOR_ROADS_DIR:\", MAJOR_ROADS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee466a",
   "metadata": {},
   "source": [
    "### D1 OS Open Greenspace polygons (Manual download)\n",
    "Used as an independent, authoritative greenspace layer for external validation of GreenScore at matched spatial support. Manual download is required due to licence acceptance and the absence of a stable public API.\n",
    "\n",
    "**Steps to download:**\n",
    "- Open the official OS Data Hub download page: https://osdatahub.os.uk/data/downloads/open/OpenGreenspace\n",
    "- In Specify an area: Select TQ (100 km tile covering Greater London)\n",
    "- In Data format : Choose ESRI Shapefile\n",
    "- Click Download and move the zip file at: `./data/raw/os_open_greenspace`\n",
    "- Note: do not unzip, just move the zip file to `./data/raw/os_open_greenspace`\n",
    "\n",
    "\n",
    "Expected result after running the next cell\n",
    "- A clean extracted folder: `data/raw/os_open_greenspace/opgrsp_essh_tq_extracted/`\n",
    "- A detected GreenspaceSite shapefile path printed in the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071fa6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greenspace extract folder already exists: /home/sai/test/notebook_test/data/raw/os_open_greenspace/opgrsp_essh_tq_extracted\n",
      "OS Open Greenspace ready\n",
      "Extracted folder: /home/sai/test/notebook_test/data/raw/os_open_greenspace/opgrsp_essh_tq_extracted\n",
      "GreenspaceSite shapefile: /home/sai/test/notebook_test/data/raw/os_open_greenspace/opgrsp_essh_tq_extracted/data/TQ_GreenspaceSite.shp\n",
      "Provenance: /home/sai/test/notebook_test/data/raw/provenance_phaseD_downloads/provenance_os_open_greenspace.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# D1.1 Data preparation: OS Open Greenspace (manual download)\n",
    "# Normalise to a stable folder name and stable shapefile paths\n",
    "# ============================================================\n",
    "\n",
    "GREENS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# The downloaded zip name can vary. Prefer a stable name if you use one.\n",
    "PREFERRED_ZIP = GREENS_DIR / \"opgrsp_essh_tq.zip\"\n",
    "\n",
    "def pick_greens_zip() -> Path:\n",
    "    if PREFERRED_ZIP.exists() and PREFERRED_ZIP.stat().st_size > 0:\n",
    "        return PREFERRED_ZIP\n",
    "    zips = sorted([p for p in GREENS_DIR.glob(\"*.zip\") if p.stat().st_size > 0])\n",
    "    if not zips:\n",
    "        raise FileNotFoundError(\n",
    "            \"Missing OS Open Greenspace zip.\\n\"\n",
    "            \"Download from OS Data Hub (tile TQ, ESRI Shapefile) and place the zip into:\\n\"\n",
    "            f\"  {GREENS_DIR}\\n\"\n",
    "            \"Optional: rename it to opgrsp_essh_tq.zip for clarity.\"\n",
    "        )\n",
    "    return zips[0]\n",
    "\n",
    "ZIP_PATH = pick_greens_zip()\n",
    "\n",
    "# If final folder missing, create it from extraction\n",
    "if not GREENS_EXTRACT_DIR.exists():\n",
    "    tmp = GREENS_DIR / \"_tmp_extract\"\n",
    "    if tmp.exists():\n",
    "        shutil.rmtree(tmp)\n",
    "    tmp.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Extracting:\", ZIP_PATH.name)\n",
    "    with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "        z.extractall(tmp)\n",
    "\n",
    "    # If there is a single top folder, move it. Otherwise keep the tmp content.\n",
    "    top_dirs = [p for p in tmp.iterdir() if p.is_dir()]\n",
    "    if len(top_dirs) == 1:\n",
    "        shutil.move(str(top_dirs[0]), str(GREENS_EXTRACT_DIR))\n",
    "        shutil.rmtree(tmp)\n",
    "    else:\n",
    "        shutil.move(str(tmp), str(GREENS_EXTRACT_DIR))\n",
    "\n",
    "else:\n",
    "    print(\"Greenspace extract folder already exists:\", GREENS_EXTRACT_DIR)\n",
    "\n",
    "# Validate we can locate the GreenspaceSite shapefile\n",
    "expected = GREENS_EXTRACT_DIR / \"data\" / \"TQ_GreenspaceSite.shp\"\n",
    "if expected.exists():\n",
    "    SITE_SHP = expected\n",
    "else:\n",
    "    candidates = list(GREENS_EXTRACT_DIR.rglob(\"*GreenspaceSite*.shp\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find GreenspaceSite shapefile after extraction.\\n\"\n",
    "            f\"Searched under: {GREENS_EXTRACT_DIR}\"\n",
    "        )\n",
    "    SITE_SHP = candidates[0]\n",
    "\n",
    "prov = {\n",
    "    \"created_at_utc\": now_utc_iso(),\n",
    "    \"dataset\": \"OS Open Greenspace (tile TQ, ESRI Shapefile)\",\n",
    "    \"method\": \"manual_download_then_extract\",\n",
    "    \"zip_used\": str(ZIP_PATH),\n",
    "    \"zip_sha256\": sha256_file(ZIP_PATH),\n",
    "    \"extract_dir\": str(GREENS_EXTRACT_DIR),\n",
    "    \"greenspace_site_shp\": str(SITE_SHP)\n",
    "}\n",
    "PROV_GREENS.write_text(json.dumps(prov, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"OS Open Greenspace ready\")\n",
    "print(\"Extracted folder:\", GREENS_EXTRACT_DIR)\n",
    "print(\"GreenspaceSite shapefile:\", SITE_SHP)\n",
    "print(\"Provenance:\", PROV_GREENS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1311dd",
   "metadata": {},
   "source": [
    "### D2 LAEI 2019 Focus Areas (Automation download)\n",
    "Independent policy layer used for convergent validation. ComfortScore is expected to be lower inside LAEI focus areas.\n",
    "\n",
    "**Steps to download:**\n",
    "- Open the official website: https://data.london.gov.uk/dataset/london-atmospheric-emissions-inventory-laei-2019-air-quality-foc-2zj76#\n",
    "- Look for GIS file (2. GIS files  (40.61 kB))\n",
    "- Direct download link : https://data.london.gov.uk/download/2zj76/36d88eac-849b-400a-ae44-2dc93bdb966d/2.%20GIS%20files.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd77068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://data.london.gov.uk/download/2zj76/36d88eac-849b-400a-ae44-2dc93bdb966d/2.%20GIS%20files.zip\n",
      "LAEI zip status: downloaded | /home/sai/test/notebook_test/data/raw/laei_focus_areas/laei_2019_focus_areas.zip\n",
      "Extracting into: /home/sai/test/notebook_test/data/raw/laei_focus_areas/laei_gis\n",
      "LAEI Focus Areas ready\n",
      "Extracted folder: /home/sai/test/notebook_test/data/raw/laei_focus_areas/laei_gis\n",
      "Selected shapefile: /home/sai/test/notebook_test/data/raw/laei_focus_areas/laei_gis/2. GIS files/LAEI2019_FocusAreas.shp\n",
      "Provenance: /home/sai/test/notebook_test/data/raw/provenance_phaseD_downloads/provenance_laei_focus_areas.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# D2.1 Download and extract: LAEI 2019 Focus Areas\n",
    "# Robust to zip structure changes, extracts into a stable folder\n",
    "# ============================================================\n",
    "\n",
    "LAEI_ZIP = LAEI_DIR / \"laei_2019_focus_areas.zip\"\n",
    "\n",
    "LAEI_URL = (\n",
    "    \"https://data.london.gov.uk/download/2zj76/\"\n",
    "    \"36d88eac-849b-400a-ae44-2dc93bdb966d/\"\n",
    "    \"2.%20GIS%20files.zip\"\n",
    ")\n",
    "\n",
    "def download_file(url: str, out_path: Path, timeout_s: int = 90):\n",
    "    out_path = Path(out_path)\n",
    "    if out_path.exists() and out_path.stat().st_size > 0:\n",
    "        return \"already_present\"\n",
    "    print(\"Downloading:\", url)\n",
    "    with requests.get(url, stream=True, timeout=timeout_s) as r:\n",
    "        r.raise_for_status()\n",
    "        with out_path.open(\"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 256):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    if out_path.stat().st_size == 0:\n",
    "        raise RuntimeError(\"Downloaded file is empty\")\n",
    "    return \"downloaded\"\n",
    "\n",
    "status = download_file(LAEI_URL, LAEI_ZIP)\n",
    "print(\"LAEI zip status:\", status, \"|\", LAEI_ZIP)\n",
    "\n",
    "if not LAEI_EXTRACT_DIR.exists():\n",
    "    LAEI_EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Extracting into:\", LAEI_EXTRACT_DIR)\n",
    "    with zipfile.ZipFile(LAEI_ZIP, \"r\") as z:\n",
    "        z.extractall(LAEI_EXTRACT_DIR)\n",
    "else:\n",
    "    print(\"LAEI extract folder already exists:\", LAEI_EXTRACT_DIR)\n",
    "\n",
    "# Find a shapefile to confirm content\n",
    "shps = sorted(LAEI_EXTRACT_DIR.rglob(\"*.shp\"))\n",
    "if not shps:\n",
    "    raise FileNotFoundError(\"LAEI shapefile not found after extraction\")\n",
    "\n",
    "# Prefer a file that looks like Focus Areas if available\n",
    "preferred = None\n",
    "for p in shps:\n",
    "    if \"focus\" in p.name.lower() and \"area\" in p.name.lower():\n",
    "        preferred = p\n",
    "        break\n",
    "LAEI_SHP = preferred if preferred else shps[0]\n",
    "\n",
    "prov = {\n",
    "    \"created_at_utc\": now_utc_iso(),\n",
    "    \"dataset\": \"LAEI 2019 Air Quality Focus Areas\",\n",
    "    \"method\": \"direct_download_then_extract\",\n",
    "    \"dataset_page\": \"https://data.london.gov.uk/dataset/london-atmospheric-emissions-inventory-laei-2019-air-quality-foc-2zj76#\",\n",
    "    \"direct_url\": LAEI_URL,\n",
    "    \"zip_path\": str(LAEI_ZIP),\n",
    "    \"zip_sha256\": sha256_file(LAEI_ZIP),\n",
    "    \"extract_dir\": str(LAEI_EXTRACT_DIR),\n",
    "    \"shapefile_selected\": str(LAEI_SHP)\n",
    "}\n",
    "PROV_LAEI.write_text(json.dumps(prov, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"LAEI Focus Areas ready\")\n",
    "print(\"Extracted folder:\", LAEI_EXTRACT_DIR)\n",
    "print(\"Selected shapefile:\", LAEI_SHP)\n",
    "print(\"Provenance:\", PROV_LAEI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af2bce",
   "metadata": {},
   "source": [
    "### D3 PTAL Public Transport Accessibility Levels (Automation download)\n",
    "\n",
    "A diagnostic accessibility proxy.\n",
    "Used cautiously to illustrate construct mismatch with the wheelchair tagging.\n",
    "\n",
    " - Dataset page : https://data.london.gov.uk/dataset/public-transport-accessibility-levels-24rz6/\n",
    " - Download : PTAL Grid Values.zip  (8.59 MB)\n",
    " - Extract at : data/raw/ptal/\n",
    " - Direct download link : https://data.london.gov.uk/download/24rz6/514d2847-94a8-4b9d-8a70-fdded01719a0/2015%20%20PTALs%20Grid%20Values.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e577385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://data.london.gov.uk/download/24rz6/514d2847-94a8-4b9d-8a70-fdded01719a0/2015%20%20PTALs%20Grid%20Values.zip\n",
      "PTAL zip status: downloaded | /home/sai/test/notebook_test/data/raw/ptal/ptal_grid_values.zip\n",
      "Extracting into: /home/sai/test/notebook_test/data/raw/ptal/ptal_grid_values\n",
      "PTAL ready\n",
      "Extracted folder: /home/sai/test/notebook_test/data/raw/ptal/ptal_grid_values\n",
      "Detected TAB: /home/sai/test/notebook_test/data/raw/ptal/ptal_grid_values/2015  PTALs Contours 280515.TAB\n",
      "Provenance: /home/sai/test/notebook_test/data/raw/provenance_phaseD_downloads/provenance_ptal.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# D3.1 Download and extract: PTAL Grid Values\n",
    "# ============================================================\n",
    "\n",
    "PTAL_ZIP = PTAL_DIR / \"ptal_grid_values.zip\"\n",
    "\n",
    "PTAL_URL = (\n",
    "    \"https://data.london.gov.uk/download/24rz6/\"\n",
    "    \"514d2847-94a8-4b9d-8a70-fdded01719a0/\"\n",
    "    \"2015%20%20PTALs%20Grid%20Values.zip\"\n",
    ")\n",
    "\n",
    "status = download_file(PTAL_URL, PTAL_ZIP)\n",
    "print(\"PTAL zip status:\", status, \"|\", PTAL_ZIP)\n",
    "\n",
    "if not PTAL_EXTRACT_DIR.exists():\n",
    "    PTAL_EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Extracting into:\", PTAL_EXTRACT_DIR)\n",
    "    with zipfile.ZipFile(PTAL_ZIP, \"r\") as z:\n",
    "        z.extractall(PTAL_EXTRACT_DIR)\n",
    "else:\n",
    "    print(\"PTAL extract folder already exists:\", PTAL_EXTRACT_DIR)\n",
    "\n",
    "# Confirm expected MapInfo TAB exists somewhere\n",
    "tabs = sorted(PTAL_EXTRACT_DIR.rglob(\"*.TAB\")) + sorted(PTAL_EXTRACT_DIR.rglob(\"*.tab\"))\n",
    "PTAL_TAB = tabs[0] if tabs else None\n",
    "\n",
    "prov = {\n",
    "    \"created_at_utc\": now_utc_iso(),\n",
    "    \"dataset\": \"PTAL Grid Values\",\n",
    "    \"method\": \"direct_download_then_extract\",\n",
    "    \"dataset_page\": \"https://data.london.gov.uk/dataset/public-transport-accessibility-levels-24rz6/\",\n",
    "    \"direct_url\": PTAL_URL,\n",
    "    \"zip_path\": str(PTAL_ZIP),\n",
    "    \"zip_sha256\": sha256_file(PTAL_ZIP),\n",
    "    \"extract_dir\": str(PTAL_EXTRACT_DIR),\n",
    "    \"tab_file_detected\": str(PTAL_TAB) if PTAL_TAB else None\n",
    "}\n",
    "PROV_PTAL.write_text(json.dumps(prov, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"PTAL ready\")\n",
    "print(\"Extracted folder:\", PTAL_EXTRACT_DIR)\n",
    "print(\"Detected TAB:\", PTAL_TAB)\n",
    "print(\"Provenance:\", PROV_PTAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce5a41",
   "metadata": {},
   "source": [
    "### D4 OSM major roads cache for Camden and Islington\n",
    "\n",
    "This is generated from your existing Geofabrik Greater London PBF.\n",
    "Uses the venue footprint to define a buffered AOI, then extracts only major highway classes.\n",
    "\n",
    "Output: `data/raw/osm_major_roads/major_roads_camden_islington.gpkg`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92be8e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading venues and building AOI\n",
      "AOI bbox WGS84: (-0.24825063505740577, 51.490368436869396, -0.04099452782589048, 51.59920692189553)\n",
      "Extracting roads using pyrosm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sai/miniconda3/envs/dft/lib/python3.11/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/sai/test/notebook_test/data/raw/osm_major_roads/major_roads_camden_islington.gpkg | rows: 12321\n",
      "Provenance: /home/sai/test/notebook_test/data/raw/provenance_phaseD_downloads/provenance_osm_major_roads.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# D4.1 Build OSM major roads cache as a GeoPackage (UPDATED)\n",
    "# Fix: pyrosm expects bounding_box as a list or Shapely Polygon, not a tuple\n",
    "# This cell does not download anything\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "try:\n",
    "    import pyrosm\n",
    "    PYROSM_OK = True\n",
    "except Exception as e:\n",
    "    PYROSM_OK = False\n",
    "    PYROSM_ERR = str(e)\n",
    "\n",
    "OUT_LAYER = \"major_roads\"\n",
    "AOI_BUFFER_M = 2500\n",
    "REFRESH_MAJOR_ROADS = False\n",
    "\n",
    "major_highways = [\n",
    "    \"motorway\", \"motorway_link\",\n",
    "    \"trunk\", \"trunk_link\",\n",
    "    \"primary\", \"primary_link\",\n",
    "    \"secondary\", \"secondary_link\",\n",
    "    \"tertiary\", \"tertiary_link\",\n",
    "]\n",
    "\n",
    "def now_utc_iso():\n",
    "    return datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "# Checks\n",
    "if not OSM_PBF.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing OSM PBF. Expected:\\n\"\n",
    "        f\"  {OSM_PBF}\\n\"\n",
    "        \"Place the Greater London .osm.pbf into data/raw/osm/ then rerun.\"\n",
    "    )\n",
    "\n",
    "if not VENUES_CLEAN.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing venues_clean.geojson. Expected:\\n\"\n",
    "        f\"  {VENUES_CLEAN}\\n\"\n",
    "        \"Run Phase A first, then rerun.\"\n",
    "    )\n",
    "\n",
    "if not PYROSM_OK:\n",
    "    raise RuntimeError(\n",
    "        \"pyrosm is not installed in this environment.\\n\"\n",
    "        \"Install it, then rerun:\\n\"\n",
    "        \"  pip install pyrosm\\n\"\n",
    "        f\"Import error: {PYROSM_ERR}\"\n",
    "    )\n",
    "\n",
    "if MAJOR_ROADS_GPKG.exists() and MAJOR_ROADS_GPKG.stat().st_size > 0 and (not REFRESH_MAJOR_ROADS):\n",
    "    print(\"Major roads cache already present:\", MAJOR_ROADS_GPKG)\n",
    "else:\n",
    "    print(\"Reading venues and building AOI\")\n",
    "\n",
    "    venues = gpd.read_file(VENUES_CLEAN)\n",
    "    if venues.crs is None:\n",
    "        raise ValueError(\"venues_clean.geojson has no CRS\")\n",
    "\n",
    "    venues_27700 = venues.to_crs(\"EPSG:27700\")\n",
    "    try:\n",
    "        geom = venues_27700.geometry.union_all()\n",
    "    except Exception:\n",
    "        geom = venues_27700.unary_union\n",
    "\n",
    "    aoi_27700 = geom.convex_hull.buffer(float(AOI_BUFFER_M))\n",
    "\n",
    "    # Convert AOI to WGS84\n",
    "    aoi_wgs = gpd.GeoSeries([aoi_27700], crs=\"EPSG:27700\").to_crs(\"EPSG:4326\").iloc[0]\n",
    "    minx, miny, maxx, maxy = aoi_wgs.bounds\n",
    "\n",
    "    # pyrosm accepts a list [minx, miny, maxx, maxy] OR a shapely polygon\n",
    "    bbox_list = [float(minx), float(miny), float(maxx), float(maxy)]\n",
    "    bbox_poly = box(*bbox_list)\n",
    "\n",
    "    print(\"AOI bbox WGS84:\", tuple(bbox_list))\n",
    "    print(\"Extracting roads using pyrosm\")\n",
    "\n",
    "    # Use polygon form for maximum compatibility\n",
    "    osm = pyrosm.OSM(str(OSM_PBF), bounding_box=bbox_poly)\n",
    "\n",
    "    roads = osm.get_network(\n",
    "        network_type=\"driving\",\n",
    "        extra_attributes=[\"highway\", \"name\", \"ref\"],\n",
    "    )\n",
    "\n",
    "    if roads is None or len(roads) == 0:\n",
    "        raise RuntimeError(\"pyrosm returned 0 road edges inside the AOI\")\n",
    "\n",
    "    if roads.crs is None:\n",
    "        roads = roads.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "\n",
    "    roads = roads[roads[\"highway\"].astype(str).isin(major_highways)].copy()\n",
    "    if len(roads) == 0:\n",
    "        raise RuntimeError(\"0 major road features after highway class filter\")\n",
    "\n",
    "    # Clip in EPSG:27700 for stable metric geometry\n",
    "    roads_27700 = roads.to_crs(\"EPSG:27700\")\n",
    "    roads_27700 = gpd.clip(roads_27700, aoi_27700)\n",
    "    roads_27700 = roads_27700[roads_27700.geometry.notna() & (~roads_27700.geometry.is_empty)].copy()\n",
    "\n",
    "    keep_cols = [c for c in [\"highway\", \"name\", \"ref\", \"geometry\"] if c in roads_27700.columns]\n",
    "    roads_27700 = roads_27700[keep_cols].copy()\n",
    "\n",
    "    if len(roads_27700) == 0:\n",
    "        raise RuntimeError(\"0 road features remain after AOI clip\")\n",
    "\n",
    "    if MAJOR_ROADS_GPKG.exists():\n",
    "        try:\n",
    "            MAJOR_ROADS_GPKG.unlink()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    roads_27700.to_file(MAJOR_ROADS_GPKG, layer=OUT_LAYER, driver=\"GPKG\")\n",
    "\n",
    "    prov = {\n",
    "        \"created_at_utc\": now_utc_iso(),\n",
    "        \"dataset\": \"OSM major roads (derived)\",\n",
    "        \"method\": \"pyrosm_from_existing_pbf\",\n",
    "        \"input_osm_pbf\": str(OSM_PBF),\n",
    "        \"input_venues\": str(VENUES_CLEAN),\n",
    "        \"aoi_buffer_m\": float(AOI_BUFFER_M),\n",
    "        \"aoi_bbox_wgs84\": {\"minx\": float(minx), \"miny\": float(miny), \"maxx\": float(maxx), \"maxy\": float(maxy)},\n",
    "        \"major_highway_classes\": major_highways,\n",
    "        \"output_gpkg\": str(MAJOR_ROADS_GPKG),\n",
    "        \"output_layer\": OUT_LAYER,\n",
    "        \"output_crs\": \"EPSG:27700\",\n",
    "        \"n_features\": int(len(roads_27700)),\n",
    "    }\n",
    "    PROV_ROADS.write_text(json.dumps(prov, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"Saved:\", MAJOR_ROADS_GPKG, \"| rows:\", len(roads_27700))\n",
    "    print(\"Provenance:\", PROV_ROADS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619fc2d",
   "metadata": {},
   "source": [
    "### D5 Checklist and input audit\n",
    "\n",
    "- It reports what exists and what is missing.\n",
    "- It only hard fails if the core pipeline inputs are missing.\n",
    "- Missing external datasets are reported as missing, not treated as a crash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cd9e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>exists</th>\n",
       "      <th>type</th>\n",
       "      <th>size_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>external</td>\n",
       "      <td>LAEI focus areas extract folder</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/laei_foc...</td>\n",
       "      <td>True</td>\n",
       "      <td>dir</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>external</td>\n",
       "      <td>OS Open Greenspace extract folder</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/os_open_...</td>\n",
       "      <td>True</td>\n",
       "      <td>dir</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>external</td>\n",
       "      <td>OSM major roads gpkg</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/osm_majo...</td>\n",
       "      <td>True</td>\n",
       "      <td>file</td>\n",
       "      <td>3.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>external</td>\n",
       "      <td>PTAL extract folder</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/ptal/pta...</td>\n",
       "      <td>True</td>\n",
       "      <td>dir</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>provenance</td>\n",
       "      <td>LAEI provenance</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/provenan...</td>\n",
       "      <td>True</td>\n",
       "      <td>file</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>provenance</td>\n",
       "      <td>Major roads provenance</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/provenan...</td>\n",
       "      <td>True</td>\n",
       "      <td>file</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>provenance</td>\n",
       "      <td>OS Greenspace provenance</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/provenan...</td>\n",
       "      <td>True</td>\n",
       "      <td>file</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>provenance</td>\n",
       "      <td>PTAL provenance</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/provenan...</td>\n",
       "      <td>True</td>\n",
       "      <td>file</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>required</td>\n",
       "      <td>greater-london osm.pbf</td>\n",
       "      <td>/home/sai/test/notebook_test/data/raw/osm/grea...</td>\n",
       "      <td>True</td>\n",
       "      <td>file</td>\n",
       "      <td>115.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>required</td>\n",
       "      <td>venues_clean.geojson</td>\n",
       "      <td>/home/sai/test/notebook_test/data/processed/ve...</td>\n",
       "      <td>True</td>\n",
       "      <td>file</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group                               name  \\\n",
       "0    external    LAEI focus areas extract folder   \n",
       "1    external  OS Open Greenspace extract folder   \n",
       "2    external               OSM major roads gpkg   \n",
       "3    external                PTAL extract folder   \n",
       "4  provenance                    LAEI provenance   \n",
       "5  provenance             Major roads provenance   \n",
       "6  provenance           OS Greenspace provenance   \n",
       "7  provenance                    PTAL provenance   \n",
       "8    required             greater-london osm.pbf   \n",
       "9    required               venues_clean.geojson   \n",
       "\n",
       "                                                path  exists  type  size_mb  \n",
       "0  /home/sai/test/notebook_test/data/raw/laei_foc...    True   dir      NaN  \n",
       "1  /home/sai/test/notebook_test/data/raw/os_open_...    True   dir      NaN  \n",
       "2  /home/sai/test/notebook_test/data/raw/osm_majo...    True  file    3.551  \n",
       "3  /home/sai/test/notebook_test/data/raw/ptal/pta...    True   dir      NaN  \n",
       "4  /home/sai/test/notebook_test/data/raw/provenan...    True  file    0.001  \n",
       "5  /home/sai/test/notebook_test/data/raw/provenan...    True  file    0.001  \n",
       "6  /home/sai/test/notebook_test/data/raw/provenan...    True  file    0.001  \n",
       "7  /home/sai/test/notebook_test/data/raw/provenan...    True  file    0.001  \n",
       "8  /home/sai/test/notebook_test/data/raw/osm/grea...    True  file  115.500  \n",
       "9  /home/sai/test/notebook_test/data/processed/ve...    True  file    0.875  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/sai/test/notebook_test\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# D5.1 Checklist and input audit\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def file_status(p: Path) -> dict:\n",
    "    p = Path(p)\n",
    "    exists = p.exists()\n",
    "    is_dir = exists and p.is_dir()\n",
    "    is_file = exists and p.is_file()\n",
    "    size_mb = None\n",
    "    if is_file:\n",
    "        size_mb = round(p.stat().st_size / (1024 * 1024), 3)\n",
    "    return {\n",
    "        \"path\": str(p),\n",
    "        \"exists\": bool(exists),\n",
    "        \"type\": \"dir\" if is_dir else \"file\",\n",
    "        \"size_mb\": size_mb,\n",
    "    }\n",
    "\n",
    "items = [\n",
    "    (\"required\", \"venues_clean.geojson\", VENUES_CLEAN),\n",
    "    (\"required\", \"greater-london osm.pbf\", OSM_PBF),\n",
    "\n",
    "    (\"external\", \"OS Open Greenspace extract folder\", GREENS_EXTRACT_DIR),\n",
    "    (\"external\", \"LAEI focus areas extract folder\", LAEI_EXTRACT_DIR),\n",
    "    (\"external\", \"PTAL extract folder\", PTAL_EXTRACT_DIR),\n",
    "    (\"external\", \"OSM major roads gpkg\", MAJOR_ROADS_GPKG),\n",
    "\n",
    "    (\"provenance\", \"OS Greenspace provenance\", PROV_GREENS),\n",
    "    (\"provenance\", \"LAEI provenance\", PROV_LAEI),\n",
    "    (\"provenance\", \"PTAL provenance\", PROV_PTAL),\n",
    "    (\"provenance\", \"Major roads provenance\", PROV_ROADS),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for group, name, path in items:\n",
    "    st = file_status(path)\n",
    "    rows.append({\"group\": group, \"name\": name, **st})\n",
    "\n",
    "status_df = pd.DataFrame(rows).sort_values([\"group\", \"name\"]).reset_index(drop=True)\n",
    "display(status_df)\n",
    "\n",
    "missing_required = status_df[(status_df[\"group\"] == \"required\") & (status_df[\"exists\"] == False)]\n",
    "if len(missing_required) > 0:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing required core inputs:\\n\" + \"\\n\".join(missing_required[\"path\"].tolist())\n",
    "    )\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dd190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
